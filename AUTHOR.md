# About the Author

These evaluation scenarios were developed by a physician with:

- **3+ years active clinical practice** across internal medicine, emergency scenarios, and outpatient care
- **Specialized training** in neuroanatomy, neurophysiology, neuropathology, neuropsychiatry, and neurosurgery
- **1+ year integrating LLMs** (ChatGPT, Claude) into clinical workflows for complex case analysis
- **3+ years building safety-critical AI systems** (Bayesian inference architectures for autonomous vehicle safety)

The scenarios are derived from real clinicianâ€“LLM interactions, de-identified and composited for educational use. They reflect failure modes observed during actual clinical decision support, not theoretical exercises.

## Why This Matters

Most LLM evaluation datasets are created by AI researchers who understand model architectures but lack clinical experience. These scenarios are created by someone who has:

1. Seen LLMs fail with actual patients on the line
2. Documented systematic failure patterns across 200+ diagnostic scenarios
3. Developed frameworks for validating AI-generated medical content against evidence-based guidelines

The result: evaluation prompts that test what actually matters in clinical reasoning, not just textbook accuracy.

## Contact

For questions, collaboration, or to discuss medical AI evaluation:

- LinkedIn: [linkedin.com/in/ajibola-folaranmi-365a77153](https://www.linkedin.com/in/ajibola-folaranmi-365a77153/)
- GitHub: [github.com/Jixx23](https://github.com/Jixx23)
